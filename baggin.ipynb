{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1025.000000\n",
      "mean        0.513171\n",
      "std         0.500070\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#importamos librerías\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dt_heart = pd.read_csv('./data/heart.csv')\n",
    "    print(dt_heart['target'].describe())\n",
    "\n",
    "    X = dt_heart.drop(['target'], axis=1)\n",
    "    y = dt_heart['target']\n",
    "\n",
    "    X_train, X_test , y_train, y_test = train_test_split(X,y, test_size=0.35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación entre Knn y Baggin Classifier\n",
      "================================================================\n",
      "KNn: 0.7437325905292479\n",
      "================================================================\n",
      "Baggin: 0.7743732590529248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreysmac/Desktop/Scikit-Learn/entorno/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "knn_class = KNeighborsClassifier().fit(X_train, y_train)\n",
    "knn_pred = knn_class.predict(X_test)\n",
    "print(\"Comparación entre Knn y Baggin Classifier\")\n",
    "print(\"=\"*64)\n",
    "print(\"KNn:\",accuracy_score(knn_pred, y_test)) #Comparamos la predicción con los datos reales\n",
    "\n",
    "#comparamos nuestro resultado con nuestro clasificador\n",
    "\n",
    "bag_class = BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=50).fit(X_train, y_train)\n",
    "bag_pred = bag_class.predict(X_test)\n",
    "print('='*64)\n",
    "print(\"Baggin:\",accuracy_score(bag_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "SCORE con KNN:  0.7270194986072424\n",
      "================================================================\n",
      "SCORE Bagging with LogisticRegression : 0.8189415041782729\n",
      "================================================================\n",
      "SCORE Bagging with SVC : 0.6573816155988857\n",
      "================================================================\n",
      "SCORE Bagging with LinearSVC : 0.841225626740947\n",
      "================================================================\n",
      "SCORE Bagging with SGD : 0.6768802228412256\n",
      "================================================================\n",
      "SCORE Bagging with KNN : 0.7994428969359332\n",
      "================================================================\n",
      "SCORE Bagging with DecisionTreeClf : 0.9721448467966574\n",
      "================================================================\n",
      "SCORE Bagging with RandomTreeForest : 0.9805013927576601\n"
     ]
    }
   ],
   "source": [
    "# Ahora compararemos lo anterior con varios algoritmos de sklearn para clasificación \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dt_heart = pd.read_csv('./data/heart.csv')\n",
    "    #print(dt_heart['target'].describe())\n",
    "\n",
    "    x = dt_heart.drop(['target'], axis=1)\n",
    "    y = dt_heart['target']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=1)\n",
    "\n",
    "    knn_class = KNeighborsClassifier().fit(x_train, y_train)\n",
    "    knn_prediction = knn_class.predict(x_test)\n",
    "    print('='*64)\n",
    "    print('SCORE con KNN: ', accuracy_score(knn_prediction, y_test))\n",
    "\n",
    "    '''bag_class = BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=50).fit(x_train, y_train) # base_estimator pide el estimador en el que va a estar basado nuestro metodo || n_estimators nos pide cuantos de estos modelos vamos a utilizar\n",
    "    bag_pred = bag_class.predict(x_test)\n",
    "    print('='*64)\n",
    "    print(accuracy_score(bag_pred, y_test))'''\n",
    "\n",
    "    estimators = {\n",
    "        'LogisticRegression' : LogisticRegression(),\n",
    "        'SVC' : SVC(),\n",
    "        'LinearSVC' : LinearSVC(),\n",
    "        'SGD' : SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5),\n",
    "        'KNN' : KNeighborsClassifier(),\n",
    "        'DecisionTreeClf' : DecisionTreeClassifier(),\n",
    "        'RandomTreeForest' : RandomForestClassifier(random_state=0)\n",
    "    }\n",
    "\n",
    "    for name, estimator in estimators.items():\n",
    "        bag_class = BaggingClassifier(base_estimator=estimator, n_estimators=50).fit(x_train, y_train)\n",
    "        bag_predict = bag_class.predict(x_test)\n",
    "        print('='*64)\n",
    "        print('SCORE Bagging with {} : {}'.format(name, accuracy_score(bag_predict, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:52:34) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e527c03d49c291424015c6d7e8fd4bc009cf0fb2c252a907ad3b578920ef556b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
